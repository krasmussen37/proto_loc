{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proto_loc Platform Validation\n",
    "\n",
    "This notebook validates that all platform components are working correctly before loading NYC taxi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Check DuckDB databases\n",
    "import duckdb\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîç Testing DuckDB databases...\")\n",
    "\n",
    "db_paths = {\n",
    "    'raw': '02_duck_db/01_raw/raw.duckdb',\n",
    "    'dev': '02_duck_db/02_dev/dev.duckdb',\n",
    "    'prod': '02_duck_db/03_prod/prod.duckdb'\n",
    "}\n",
    "\n",
    "for name, path in db_paths.items():\n",
    "    if Path(path).exists():\n",
    "        conn = duckdb.connect(path)\n",
    "        schemas = conn.execute(\"SHOW SCHEMAS\").fetchall()\n",
    "        conn.close()\n",
    "        print(f\"‚úÖ {name}: {len(schemas)} schemas\")\n",
    "    else:\n",
    "        print(f\"‚ùå {name}: Database not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Validate dbt project\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"üîç Testing dbt project...\")\n",
    "os.chdir('04_dbt')\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(['dbt', 'debug'], capture_output=True, text=True, timeout=30)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ dbt project configured correctly\")\n",
    "    else:\n",
    "        print(f\"‚ùå dbt issues: {result.stderr}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå dbt test failed: {e}\")\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Check Cube.js configuration\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"üîç Testing Cube.js configuration...\")\n",
    "\n",
    "cube_config = '05_cube_dev/cube.js'\n",
    "if Path(cube_config).exists():\n",
    "    print(\"‚úÖ Cube.js configuration found\")\n",
    "else:\n",
    "    print(\"‚ùå Cube.js configuration missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Validate environment\n",
    "print(\"üîç Checking environment...\")\n",
    "\n",
    "# Check if .env exists\n",
    "if Path('.env').exists():\n",
    "    print(\"‚úÖ .env file found\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  .env file missing (copy from .env.example)\")\n",
    "\n",
    "# Check OpenAI key\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_key:\n",
    "    print(\"‚úÖ OpenAI API key configured\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  OpenAI API key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: Quick platform health check\n",
    "print(\"üéâ Platform validation complete!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run: python init_duckdb.py\")\n",
    "print(\"2. Run: docker-compose up\")\n",
    "print(\"3. Open services at their respective ports\")\n",
    "print(\"4. Load NYC taxi data and begin development!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 6: Network Connectivity\n",
    "import socket\n",
    "\n",
    "print(\"üîç Testing network connectivity...\")\n",
    "\n",
    "services = {\n",
    "    'dagster': 3000,\n",
    "    'cube': 4000,\n",
    "    'superset': 8088\n",
    "}\n",
    "\n",
    "for service, port in services.items():\n",
    "    try:\n",
    "        s = socket.create_connection(('localhost', port), timeout=5)\n",
    "        s.close()\n",
    "        print(f\"‚úÖ {service} reachable on port {port}\")\n",
    "    except:\n",
    "        print(f\"‚ùå {service} not reachable on port {port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 7: DuckDB Concurrency Simulation\n",
    "import concurrent.futures\n",
    "\n",
    "print(\"üîç Simulating DuckDB concurrency...\")\n",
    "\n",
    "def read_query(db_path):\n",
    "    conn = duckdb.connect(db_path, read_only=True)\n",
    "    result = conn.execute(\"SELECT COUNT(*) FROM information_schema.tables\").fetchone()\n",
    "    conn.close()\n",
    "    return result\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(read_query, path) for path in db_paths.values()]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        try:\n",
    "            print(f\"‚úÖ Concurrent read successful: {future.result()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Concurrency issue: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 8: PandasAI LLM Configuration\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI, Anthropic, GoogleGemini\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"üîç Testing PandasAI LLM configuration...\")\n",
    "\n",
    "preferred = os.getenv('PREFERRED_LLM', 'openai')\n",
    "\n",
    "llm = None\n",
    "if preferred == 'openai' and os.getenv('OPENAI_API_KEY'):\n",
    "    llm = OpenAI(api_token=os.getenv('OPENAI_API_KEY'))\n",
    "elif preferred == 'anthropic' and os.getenv('ANTHROPIC_API_KEY'):\n",
    "    llm = Anthropic(api_token=os.getenv('ANTHROPIC_API_KEY'))\n",
    "elif preferred == 'gemini' and os.getenv('GEMINI_API_KEY'):\n",
    "    llm = GoogleGemini(api_token=os.getenv('GEMINI_API_KEY'))\n",
    "elif os.getenv('OPENAI_API_KEY'):\n",
    "    llm = OpenAI(api_token=os.getenv('OPENAI_API_KEY'))  # Fallback\n",
    "\n",
    "if llm:\n",
    "    df = pd.DataFrame({'test': [1, 2, 3]})\n",
    "    sdf = SmartDataframe(df, config={\"llm\": llm})\n",
    "    result = sdf.chat(\"What is the sum?\")\n",
    "    print(f\"‚úÖ PandasAI working with {preferred}: {result}\")\n",
    "else:\n",
    "    print(\"‚ùå No LLM configured - check .env keys\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
