
services:
  # Data Orchestration Service - Manages ETL/ELT pipelines and asset materialization

  dagster:
    build:
      context: ./03_dagster
      dockerfile: Dockerfile
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "${DAGSTER_PORT:-3000}:3000"  # Expose Dagster UI on configurable port (default: 3000)
    volumes:
      # Mount project code for live development
      - ./03_dagster:/app
      # Mount DuckDB databases for read/write access
      - ./02_duck_db:/app/02_duck_db
      # Mount source data directory for ingestion
      - ./01_source_data:/app/01_source_data
      # Mount Dagster home for persistent run history, schedules, and metadata
      - ./03_dagster/dagster_home:/opt/dagster/dagster_home
    environment:
      # Database path configuration - allows environment-specific overrides
      - DUCKDB_RAW_PATH=${DUCKDB_RAW_PATH:-/app/02_duck_db/01_raw/raw.duckdb}
      - DUCKDB_DEV_PATH=${DUCKDB_DEV_PATH:-/app/02_duck_db/02_dev/dev.duckdb}
      - DUCKDB_PROD_PATH=${DUCKDB_PROD_PATH:-/app/02_duck_db/03_prod/prod.duckdb}
    networks:
      - proto_loc_network
    restart: unless-stopped

  # Data Transformation Service - SQL-based data modeling with dbt
  dbt:
    build:
      context: ./04_dbt
      dockerfile: Dockerfile
    volumes:
      # Mount dbt project for live development
      - ./04_dbt:/app/04_dbt
      # Mount DuckDB databases for transformation operations
      - ./02_duck_db:/app/02_duck_db
    environment:
      # Database path configuration for dbt profiles
      - DUCKDB_RAW_PATH=${DUCKDB_RAW_PATH:-/app/02_duck_db/01_raw/raw.duckdb}
      - DUCKDB_DEV_PATH=${DUCKDB_DEV_PATH:-/app/02_duck_db/02_dev/dev.duckdb}
      - DUCKDB_PROD_PATH=${DUCKDB_PROD_PATH:-/app/02_duck_db/03_prod/prod.duckdb}
    networks:
      - proto_loc_network
    restart: unless-stopped


  # PostgreSQL: Database for Superset Metadata
  # Provides a reliable OLTP database for Superset's application data
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${SUPERSET_POSTGRES_DB:-superset}
      - POSTGRES_USER=${SUPERSET_POSTGRES_USER:-superset}
      - POSTGRES_PASSWORD=${SUPERSET_POSTGRES_PASSWORD:-superset}
    volumes:
      # Persists PostgreSQL database data
      - postgres_data:/var/lib/postgresql/data
    networks:
      - proto_loc_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${SUPERSET_POSTGRES_USER:-superset}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Superset: Data Visualization and BI Platform
  # Used for creating interactive dashboards and charts
  
  superset:
    build:
      context: ./06_superset
      dockerfile: Dockerfile
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "${SUPERSET_PORT:-8088}:8088"  # Expose Superset UI on configurable port (default: 8088)
    volumes:

      # Mounts the DuckDB databases for data access (read-only for safety)
      - ./02_duck_db:/app/02_duck_db:ro
    environment:
      # PostgreSQL connection for Superset metadata
      - SUPERSET_POSTGRES_HOST=postgres
      - SUPERSET_POSTGRES_PORT=5432
      - SUPERSET_POSTGRES_DB=${SUPERSET_POSTGRES_DB:-superset}
      - SUPERSET_POSTGRES_USER=${SUPERSET_POSTGRES_USER:-superset}
      - SUPERSET_POSTGRES_PASSWORD=${SUPERSET_POSTGRES_PASSWORD:-superset}
      # Superset application configuration
      - SUPERSET_SECRET_KEY=${SUPERSET_SECRET_KEY:-your-secret-key-here-change-me-in-production}
      - SUPERSET_USERNAME=${SUPERSET_USERNAME:-admin}
      - SUPERSET_PASSWORD=${SUPERSET_PASSWORD:-admin}
      - SUPERSET_EMAIL=${SUPERSET_EMAIL:-admin@example.com}
      # DuckDB database paths for analytics data connections
      - DUCKDB_RAW_PATH=${DUCKDB_RAW_PATH:-/app/02_duck_db/01_raw/raw.duckdb}
      - DUCKDB_DEV_PATH=${DUCKDB_DEV_PATH:-/app/02_duck_db/02_dev/dev.duckdb}
      - DUCKDB_PROD_PATH=${DUCKDB_PROD_PATH:-/app/02_duck_db/03_prod/prod.duckdb}
    networks:
      - proto_loc_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s


  # Semantic Layer Service - Metrics and API layer
  cube:
    build:
      context: ./05_cube_dev
      dockerfile: Dockerfile
    ports:
      - "${CUBE_PORT:-4000}:4000"  # Expose Cube API on configurable port (default: 4000)
    volumes:
      # Mount Cube schema definitions for live development
      - ./05_cube_dev:/app/05_cube_dev
      # Mount DuckDB databases in read-only mode (Cube only reads from prod)
      - ./02_duck_db:/app/02_duck_db:ro
    environment:
      - CUBEJS_DB_TYPE=duckdb
      # Cube connects only to production database for stable API
      - CUBEJS_DB_PATH=${DUCKDB_PROD_PATH:-/app/02_duck_db/03_prod/prod.duckdb}
    networks:
      - proto_loc_network
    restart: unless-stopped

  # AI Analysis Service - Jupyter notebooks with PandasAI integration
  jupyter:
    build:
      context: ./07_pandas_ai
      dockerfile: Dockerfile
    ports:
      - "${JUPYTER_PORT:-8888}:8888"  # Expose JupyterLab on configurable port (default: 8888)
    volumes:

      # Mount notebooks directory for persistent development
      - ./07_pandas_ai:/app/07_pandas_ai
      # Mount DuckDB databases for analysis (can read/write for experimentation)
      - ./02_duck_db:/app/02_duck_db
      # Mount source data for direct analysis
      - ./01_source_data:/app/01_source_data
    environment:
      - JUPYTER_PORT=${JUPYTER_PORT:-8888}
      # API key for PandasAI LLM integration
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # Database path configuration for notebook connections
      - DUCKDB_RAW_PATH=${DUCKDB_RAW_PATH:-/app/02_duck_db/01_raw/raw.duckdb}
      - DUCKDB_DEV_PATH=${DUCKDB_DEV_PATH:-/app/02_duck_db/02_dev/dev.duckdb}
      - DUCKDB_PROD_PATH=${DUCKDB_PROD_PATH:-/app/02_duck_db/03_prod/prod.duckdb}
    networks:
      - proto_loc_network
    restart: unless-stopped

# Named volumes for data persistence
volumes:
  # Persists Dagster's run history, logs, and metadata
  dagster_data:
    driver: local
  # Persists PostgreSQL database data for Superset metadata
  postgres_data:
    driver: local

# Shared network for all services
networks:
  proto_loc_network:
    driver: bridge
